# override.yaml
nodeSelector:
  intent: apps
  node.kubernetes.io/instance-type: c6a.xlarge # non worker node

data:
  metadataSecretName: airflow

webserverSecretKeySecretName: my-webserver-secret

workers:
  persistence:
    # Enable persistent volumes
    enabled: true
    # Volume size for worker StatefulSet
    size: 500Gi
    # If using a custom storageClass, pass name ref to all statefulSets here
    storageClassName: gp2
    # Execute init container to chown log directory.
    # This is currently only needed in kind, due to usage
    # of local-path provisioner.
    fixPermissions: false
    # Annotations to add to worker volumes
    annotations:
      volume.beta.kubernetes.io/storage-provisioner: kubernetes.io/aws-ebs

  nodeSelector:
    intent: apps
    node.kubernetes.io/instance-type: c6a.xlarge

webserver:
  defaultUser:
    enabled: true
    role: Admin
    username: admin
    email: shailendra.sharma@verse.in
    firstName: admin
    lastName: user
    password: AdminUser@123



#####

core:
  # SequentialExecutor, LocalExecutor, CeleryExecutor
  executor: CeleryExecutor
  sql_alchemy_conn: "mysql://{USERNAME}:{PASSWORD}@{MYSQL_HOST}:3306/airflow"
  dags_are_paused_at_creation: True
  load_examples: True

celery:
  #broker_url: amqp://guest:guest@{RABBITMQ_HOST}:5672/
  broker_url: sqs://{ACCESS_KEY_ID}:{SECRET_KEY}@
  celery_result_backend: db+mysql://{USERNAME}:{PASSWORD}@{MYSQL_HOST}:3306/airflow
  default_queue: {YOUR_QUEUE_NAME_HERE}



secret:
  - envName: "AIRFLOW_CONN_GCP"
    secretName: "my-airflow-connections"
    secretKey: "AIRFLOW_CONN_GCP"
  - envName: "my-env"
    secretName: "my-secret-name"
    secretKey: "my-secret-key"

extraSecrets:
  my-airflow-connections:
    data: |
      AIRFLOW_CONN_GCP: 'base64_encoded_gcp_conn_string'
  my-secret-name:
    stringData: |
      my-secret-key: my-secret